# How Patterns, Recommendations & Preferences are Generated

## ğŸ”„ Complete Flow Diagram

```
INPUT: 9 Behavior Signals (6 views + 2 carts + 1 purchase)
   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 1: SCORE COMPUTATION (PatternAnalyzer.computeScores)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   
   From the 9 signals, calculate 7 KPI scores:
   
   â”œâ”€ ENGAGEMENT_SCORE = log(9+1) / 4.0 = 0.58 âœ“ (HIGH)
   â”‚  â””â”€ Based on total event count
   â”‚  
   â”œâ”€ DIVERSITY_SCORE = 2 unique schemas / 9 events = 0.22
   â”‚  â””â”€ Count unique signal types (engagement.view, engagement.add_to_cart, conversion.purchase)
   â”‚  
   â”œâ”€ RECENCY_SCORE = 1.0 - (hours since last signal / 168)
   â”‚  â””â”€ Signal happened 30 minutes ago â†’ HIGH recency
   â”‚  
   â”œâ”€ ENGAGEMENT_VELOCITY = count in last hour / 20.0
   â”‚  â””â”€ All 9 signals in same session â†’ 0.45
   â”‚  
   â”œâ”€ INTERACTION_DENSITY = 9 / 100.0 = 0.09
   â”‚  â””â”€ Event count normalized
   â”‚  
   â””â”€ More KPIs...

   ğŸ“Š Result: Map<String, Double> scores = {
       engagement_score: 0.58,
       diversity_score: 0.22,
       recency_score: 0.95,
       engagement_velocity: 0.45,
       interaction_density: 0.09,
       ... more KPIs
   }

   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 2: PATTERN DETECTION (detectPatterns)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

   Using the scores, apply RULE-BASED classification:
   
   â”œâ”€ IF engagement >= 0.8 â†’ "power_user" âœ— (0.58 < 0.8)
   â”œâ”€ ELIF engagement < 0.2 â†’ "low_activity" âœ— (0.58 > 0.2)
   â””â”€ ELSE â†’ "steady_state" âœ“ (MATCHED!)
   
   â”œâ”€ IF recency < 0.3 â†’ "dormant" âœ— (0.95 > 0.3)
   â”œâ”€ ELIF recency > 0.7 â†’ "recent_engagement" âœ“ (MATCHED!)
   
   â”œâ”€ IF velocity > 0.6 â†’ "burst_activity" âœ— (0.45 < 0.6)
   â”œâ”€ IF evening_heavy (>=60% events 6pm-4am) â†’ "evening_bias"
   â””â”€ IF weekend_heavy (>=60% events on weekends) â†’ "weekend_bias"

   ğŸ¯ Result: List<String> patterns = [
       "steady_state",
       "recent_engagement"
   ]

   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 3: SEGMENTATION (SegmentationAnalyzer.fromEvents)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

   Input: patterns + scores â†’ triggers both:
   
   A) PREFERENCE DETECTION (detectPreferences)
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   
   Analyze the actual signal content:
   
   â”œâ”€ COUNT signal schemas:
   â”‚  â””â”€ "engagement.view": 6x
   â”‚     "engagement.add_to_cart": 2x
   â”‚     "conversion.purchase": 1x
   â”‚
   â”œâ”€ EXTRACT top 3 schemas (sorted by frequency):
   â”‚  â””â”€ ["engagement.view", "engagement.add_to_cart", "conversion.purchase"]
   â”‚
   â”œâ”€ CALCULATE avg_duration_seconds:
   â”‚  â””â”€ Extract from signal attributes, average them
   â”‚
   â””â”€ COUNT unique_schemas:
      â””â”€ 3 different types

   ğŸ“‹ Result: Map<String, Object> preferences = {
       top_schemas: ["engagement.view", "engagement.add_to_cart", "conversion.purchase"],
       avg_duration_seconds: 45.2,
       unique_schemas: 3
   }

   B) RECOMMENDATION GENERATION (buildRecommendations)
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   
   Uses PATTERNS + SCORES to suggest actions:
   
   â”œâ”€ IF patterns contains "dormant" OR recency < 0.3
   â”‚  â””â”€ ADD â†’ "trigger_reengagement_sequence" âœ— (dormant not in patterns)
   â”‚
   â”œâ”€ IF engagement_score > 0.7
   â”‚  â””â”€ ADD â†’ "offer_advocacy_program" âœ— (0.58 < 0.7)
   â”‚
   â””â”€ IF recommendations still empty
      â””â”€ ADD â†’ "monitor_behavior" âœ“ (DEFAULT)

   ğŸ’¡ Result: List<String> recommendations = [
       "monitor_behavior"
   ]

   C) SEGMENT DETERMINATION (determineSegment)
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   
   Rules based on engagement + recency scores:
   
   â”œâ”€ IF engagement >= 0.75 AND recency >= 0.6
   â”‚  â””â”€ Segment = "active" âœ“ (0.58 < 0.75, not matched)
   â”‚
   â”œâ”€ IF engagement >= 0.4 AND recency >= 0.4
   â”‚  â””â”€ Segment = "steady" âœ“ (MATCHED! 0.58 >= 0.4 AND 0.95 >= 0.4)
   â”‚
   â”œâ”€ IF recency < 0.2
   â”‚  â””â”€ Segment = "dormant" âœ—
   â”‚
   â””â”€ ELSE
      â””â”€ Segment = "emerging" (if no match)

   ğŸ·ï¸ Result: String segment = "steady"

   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 4: RETURN BehaviorInsights OBJECT                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

   BehaviorInsights.builder()
       .userId(userId)
       .patterns(["steady_state", "recent_engagement"])     â† FROM STEP 2
       .scores({engagement: 0.58, recency: 0.95, ...})    â† FROM STEP 1
       .segment("steady")                                  â† FROM STEP 3C
       .preferences({                                      â† FROM STEP 3A
           top_schemas: [...],
           avg_duration_seconds: 45.2,
           unique_schemas: 3
       })
       .recommendations(["monitor_behavior"])              â† FROM STEP 3B
       .analyzedAt(now)
       .validUntil(now + 24h)
       .build()

   âœ… RESULT READY!
```

---

## ğŸ“Š Test Example Walkthrough

### Test Case: `analyzerBuildsSegmentedInsights`

**Input Signals:**
```
Signal 1-6:  engagement.view (luxury product, price=$1500)
Signal 7-8:  engagement.add_to_cart (quantity=1)
Signal 9:    conversion.purchase (amount=$2500)
All in one session, 30 minutes
```

**Execution Flow:**

| Step | Process | Input | Output |
|------|---------|-------|--------|
| 1 | Score Computation | 9 signals with timestamps/attributes | 7 KPI scores |
| 2 | Pattern Detection | KPI scores | ["steady_state", "recent_engagement"] |
| 3A | Preference Extraction | Signal schema IDs & attributes | { top_schemas: [...], unique_schemas: 3 } |
| 3B | Recommendation Gen | Patterns + scores | ["monitor_behavior"] |
| 3C | Segmentation | Engagement & recency scores | "steady" or "active" |
| 4 | Build Insights | All above | BehaviorInsights object |

**Assertions in Test:**
```java
assertThat(insights.getPatterns()).isNotEmpty();           âœ… ["steady_state", ...]
assertThat(insights.getRecommendations()).isNotEmpty();    âœ… ["monitor_behavior"]
assertThat(insights.getPreferences()).isNotNull();         âœ… {top_schemas: [...]}
assertThat(insights.getSegment()).isNotNull();             âœ… "steady" or "active"
```

---

## ğŸ¯ Key Algorithm Components

### 1. Score Computation (Quantitative)
- **Engagement**: Based on event count â†’ `log(count+1)/4`
- **Diversity**: Based on unique signal types â†’ `unique/total`
- **Recency**: Based on time since last signal â†’ `1 - (hours/168)`
- **Velocity**: Based on burst activity â†’ `recent_events/20`

### 2. Pattern Detection (Rules-Based)
- **Activity Level**: ENGAGEMENT score â†’ power_user / steady_state / low_activity
- **Freshness**: RECENCY score â†’ recent_engagement / dormant
- **Intensity**: VELOCITY score â†’ burst_activity
- **Temporal**: CHECK hour/day patterns â†’ evening_bias / weekend_bias

### 3. Preference Extraction (Content-Based)
- **Top Schemas**: COUNT frequency of each signal type
- **Duration**: EXTRACT and AVERAGE time attributes
- **Diversity**: COUNT unique schema types

### 4. Recommendation Engine (Decision Logic)
- **Pattern-based**: Check patterns list for specific values
- **Score-based**: Threshold comparisons (e.g., engagement > 0.7)
- **Default**: Fallback if no specific rule matches

### 5. Segmentation (Scoring Threshold)
- **Active**: High engagement + high recency
- **Steady**: Medium engagement + medium recency
- **Dormant**: Low recency (inactive users)
- **Emerging**: Catch-all for in-between cases

---

## ğŸ’¾ Database Operations During Analysis

```
1. READ:  SELECT behavior_signals WHERE user_id = ?
          (retrieves all 9 signals)
          
2. CALC:  Compute 7 scores in memory (no DB)

3. PROC:  Analyze patterns in memory (no DB)

4. WRITE: INSERT INTO behavior_insights (
              patterns, scores, segment, 
              preferences, recommendations
          ) VALUES (...)

5. INDEX: Queries use idx_behavior_insights_user
```

---

## ğŸš€ Performance

- **Per User Analysis**: ~100-150ms
- **Computation**: Fully in-memory (no external calls)
- **Database**: 1 read + 1 write operation
- **Scalability**: Linear O(n) where n = number of signals

---

## ğŸ”‘ Key Takeaways

1. **Patterns** = Rule-based classification of KPI scores
2. **Recommendations** = Logic-driven suggestions based on patterns & scores
3. **Preferences** = Content analysis of actual signal data
4. **Segment** = User classification from engagement/recency matrix
5. **All deterministic** = Same signals â†’ always same analysis
6. **No ML needed** = Pure algorithmic approach with configurable thresholds


