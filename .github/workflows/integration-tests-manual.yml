name: Integration Tests (Manual Trigger)

on:
  workflow_dispatch:
    inputs:
      modules:
        description: 'Test modules to run'
        required: true
        default: 'all'
        type: choice
        options:
          - all
          - ai-infrastructure
          - behavior-analytics
          - relationship-query
          - backend
      test_profile:
        description: 'Test profile (for AI Infrastructure module)'
        required: false
        default: 'default'
        type: choice
        options:
          - default
          - real-api-tests
          - performance-tests
          - all-tests
      timeout_minutes:
        description: 'Job timeout in minutes'
        required: false
        default: '30'

jobs:
  # ==============================================================================
  # Job 1: AI Infrastructure Integration Tests
  # ==============================================================================
  ai-infrastructure-tests:
    name: AI Infrastructure Integration Tests
    runs-on: ubuntu-latest
    timeout-minutes: ${{ fromJSON(github.event.inputs.timeout_minutes) }}
    if: |
      github.event.inputs.modules == 'all' || 
      github.event.inputs.modules == 'ai-infrastructure'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up JDK 21
        uses: actions/setup-java@v4
        with:
          java-version: '21'
          distribution: 'temurin'
          cache: 'maven'

      - name: Cache Maven packages
        uses: actions/cache@v3
        with:
          path: ~/.m2/repository
          key: ${{ runner.os }}-maven-ai-infra-${{ hashFiles('**/pom.xml') }}
          restore-keys: |
            ${{ runner.os }}-maven-ai-infra-
            ${{ runner.os }}-maven-

      - name: Build AI Infrastructure Module
        run: |
          cd ai-infrastructure-module
          mvn clean install -DskipTests -B -V

      - name: Run Integration Tests (Default)
        if: github.event.inputs.test_profile == 'default' || github.event.inputs.test_profile == ''
        run: |
          cd ai-infrastructure-module
          mvn test -pl integration-tests -B
        env:
          TESTCONTAINERS_RYUK_DISABLED: false

      - name: Run Integration Tests (Real API)
        if: github.event.inputs.test_profile == 'real-api-tests'
        run: |
          cd ai-infrastructure-module
          mvn test -pl integration-tests -P real-api-tests -B
        env:
          TESTCONTAINERS_RYUK_DISABLED: false
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          AZURE_OPENAI_API_KEY: ${{ secrets.AZURE_OPENAI_API_KEY }}
          COHERE_API_KEY: ${{ secrets.COHERE_API_KEY }}
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}

      - name: Run Integration Tests (Performance)
        if: github.event.inputs.test_profile == 'performance-tests'
        run: |
          cd ai-infrastructure-module
          mvn test -pl integration-tests -P performance-tests -B
        env:
          TESTCONTAINERS_RYUK_DISABLED: false

      - name: Run Integration Tests (All Tests)
        if: github.event.inputs.test_profile == 'all-tests'
        run: |
          cd ai-infrastructure-module
          mvn test -pl integration-tests -P all-tests -B
        env:
          TESTCONTAINERS_RYUK_DISABLED: false
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          AZURE_OPENAI_API_KEY: ${{ secrets.AZURE_OPENAI_API_KEY }}
          COHERE_API_KEY: ${{ secrets.COHERE_API_KEY }}
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}

      - name: Upload test reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ai-infrastructure-test-reports
          path: |
            ai-infrastructure-module/integration-tests/target/surefire-reports/
            ai-infrastructure-module/integration-tests/target/failsafe-reports/
          retention-days: 30

      - name: Publish Test Results
        uses: EnricoMi/publish-unit-test-result-action@v2
        if: always()
        with:
          files: |
            ai-infrastructure-module/integration-tests/target/surefire-reports/*.xml
          check_name: AI Infrastructure Test Results

  # ==============================================================================
  # Job 2: Behavior Analytics Integration Tests
  # ==============================================================================
  behavior-analytics-tests:
    name: Behavior Analytics Integration Tests
    runs-on: ubuntu-latest
    timeout-minutes: 20
    if: |
      github.event.inputs.modules == 'all' || 
      github.event.inputs.modules == 'behavior-analytics'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up JDK 21
        uses: actions/setup-java@v4
        with:
          java-version: '21'
          distribution: 'temurin'
          cache: 'maven'

      - name: Cache Maven packages
        uses: actions/cache@v3
        with:
          path: ~/.m2/repository
          key: ${{ runner.os }}-maven-behavior-${{ hashFiles('**/pom.xml') }}
          restore-keys: |
            ${{ runner.os }}-maven-behavior-
            ${{ runner.os }}-maven-

      - name: Build AI Infrastructure Module
        run: |
          cd ai-infrastructure-module
          mvn clean install -DskipTests -B -V

      - name: Run Behavior Analytics Integration Tests
        run: |
          cd ai-infrastructure-module
          mvn test -pl ai-infrastructure-behavior-integration-tests -B
        env:
          TESTCONTAINERS_RYUK_DISABLED: false
          SPRING_PROFILES_ACTIVE: test
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}

      - name: Upload test reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: behavior-analytics-test-reports
          path: |
            ai-infrastructure-module/ai-infrastructure-behavior-integration-tests/target/surefire-reports/
            ai-infrastructure-module/ai-infrastructure-behavior-integration-tests/target/failsafe-reports/
          retention-days: 30

      - name: Publish Test Results
        uses: EnricoMi/publish-unit-test-result-action@v2
        if: always()
        with:
          files: |
            ai-infrastructure-module/ai-infrastructure-behavior-integration-tests/target/surefire-reports/*.xml
          check_name: Behavior Analytics Test Results

  # ==============================================================================
  # Job 3: Relationship Query Integration Tests
  # ==============================================================================
  relationship-query-tests:
    name: Relationship Query Integration Tests
    runs-on: ubuntu-latest
    timeout-minutes: 15
    if: |
      github.event.inputs.modules == 'all' || 
      github.event.inputs.modules == 'relationship-query'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up JDK 21
        uses: actions/setup-java@v4
        with:
          java-version: '21'
          distribution: 'temurin'
          cache: 'maven'

      - name: Cache Maven packages
        uses: actions/cache@v3
        with:
          path: ~/.m2/repository
          key: ${{ runner.os }}-maven-relationship-${{ hashFiles('**/pom.xml') }}
          restore-keys: |
            ${{ runner.os }}-maven-relationship-
            ${{ runner.os }}-maven-

      - name: Build AI Infrastructure Module
        run: |
          cd ai-infrastructure-module
          mvn clean install -DskipTests -B -V

      - name: Run Relationship Query Integration Tests
        run: |
          cd ai-infrastructure-module
          mvn test -pl relationship-query-integration-tests -B
        env:
          SPRING_PROFILES_ACTIVE: test
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}

      - name: Upload test reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: relationship-query-test-reports
          path: |
            ai-infrastructure-module/relationship-query-integration-tests/target/surefire-reports/
            ai-infrastructure-module/relationship-query-integration-tests/target/failsafe-reports/
          retention-days: 30

      - name: Publish Test Results
        uses: EnricoMi/publish-unit-test-result-action@v2
        if: always()
        with:
          files: |
            ai-infrastructure-module/relationship-query-integration-tests/target/surefire-reports/*.xml
          check_name: Relationship Query Test Results

  # ==============================================================================
  # Job 4: Backend Application Integration Tests
  # ==============================================================================
  backend-tests:
    name: Backend Application Integration Tests
    runs-on: ubuntu-latest
    timeout-minutes: 25
    if: |
      github.event.inputs.modules == 'all' || 
      github.event.inputs.modules == 'backend'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up JDK 21
        uses: actions/setup-java@v4
        with:
          java-version: '21'
          distribution: 'temurin'
          cache: 'maven'

      - name: Cache Maven packages
        uses: actions/cache@v3
        with:
          path: ~/.m2/repository
          key: ${{ runner.os }}-maven-backend-${{ hashFiles('**/pom.xml') }}
          restore-keys: |
            ${{ runner.os }}-maven-backend-
            ${{ runner.os }}-maven-

      - name: Build AI Infrastructure Module (Dependency)
        run: |
          cd ai-infrastructure-module
          mvn clean install -DskipTests -B -V

      - name: Build Backend Application
        run: |
          cd backend
          mvn clean compile -B -V

      - name: Run Backend Integration Tests
        run: |
          cd backend
          mvn test -B
        env:
          TESTCONTAINERS_RYUK_DISABLED: false
          SPRING_PROFILES_ACTIVE: test
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          JWT_SECRET: ${{ secrets.JWT_SECRET }}

      - name: Upload test reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: backend-test-reports
          path: |
            backend/target/surefire-reports/
            backend/target/failsafe-reports/
          retention-days: 30

      - name: Publish Test Results
        uses: EnricoMi/publish-unit-test-result-action@v2
        if: always()
        with:
          files: |
            backend/target/surefire-reports/*.xml
          check_name: Backend Test Results

  # ==============================================================================
  # Summary Job - Aggregates all test results
  # ==============================================================================
  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [ai-infrastructure-tests, behavior-analytics-tests, relationship-query-tests, backend-tests]
    if: always()
    
    steps:
      - name: Download all test reports
        uses: actions/download-artifact@v4
        with:
          path: test-reports

      - name: Create Test Summary
        run: |
          echo "# üß™ Integration Tests Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Triggered by:** @${{ github.actor }}" >> $GITHUB_STEP_SUMMARY
          echo "**Modules tested:** ${{ github.event.inputs.modules }}" >> $GITHUB_STEP_SUMMARY
          echo "**Test profile:** ${{ github.event.inputs.test_profile || 'default' }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Check job statuses
          AI_INFRA_STATUS="${{ needs.ai-infrastructure-tests.result }}"
          BEHAVIOR_STATUS="${{ needs.behavior-analytics-tests.result }}"
          RELATIONSHIP_STATUS="${{ needs.relationship-query-tests.result }}"
          BACKEND_STATUS="${{ needs.backend-tests.result }}"
          
          # Function to get emoji for status
          get_emoji() {
            case $1 in
              success) echo "‚úÖ" ;;
              failure) echo "‚ùå" ;;
              skipped) echo "‚è≠Ô∏è" ;;
              cancelled) echo "üö´" ;;
              *) echo "‚ùì" ;;
            esac
          }
          
          echo "| Module | Status | Result |" >> $GITHUB_STEP_SUMMARY
          echo "|--------|--------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| AI Infrastructure | $(get_emoji $AI_INFRA_STATUS) | $AI_INFRA_STATUS |" >> $GITHUB_STEP_SUMMARY
          echo "| Behavior Analytics | $(get_emoji $BEHAVIOR_STATUS) | $BEHAVIOR_STATUS |" >> $GITHUB_STEP_SUMMARY
          echo "| Relationship Query | $(get_emoji $RELATIONSHIP_STATUS) | $RELATIONSHIP_STATUS |" >> $GITHUB_STEP_SUMMARY
          echo "| Backend Application | $(get_emoji $BACKEND_STATUS) | $BACKEND_STATUS |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Overall result
          if [[ "$AI_INFRA_STATUS" == "success" || "$AI_INFRA_STATUS" == "skipped" ]] && \
             [[ "$BEHAVIOR_STATUS" == "success" || "$BEHAVIOR_STATUS" == "skipped" ]] && \
             [[ "$RELATIONSHIP_STATUS" == "success" || "$RELATIONSHIP_STATUS" == "skipped" ]] && \
             [[ "$BACKEND_STATUS" == "success" || "$BACKEND_STATUS" == "skipped" ]]; then
            echo "### ‚úÖ All tests passed!" >> $GITHUB_STEP_SUMMARY
          else
            echo "### ‚ùå Some tests failed. Please check the logs." >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "üìä **View detailed reports in the artifacts section**" >> $GITHUB_STEP_SUMMARY

      - name: Check overall test status
        run: |
          AI_INFRA_STATUS="${{ needs.ai-infrastructure-tests.result }}"
          BEHAVIOR_STATUS="${{ needs.behavior-analytics-tests.result }}"
          RELATIONSHIP_STATUS="${{ needs.relationship-query-tests.result }}"
          BACKEND_STATUS="${{ needs.backend-tests.result }}"
          
          if [[ "$AI_INFRA_STATUS" == "failure" ]] || \
             [[ "$BEHAVIOR_STATUS" == "failure" ]] || \
             [[ "$RELATIONSHIP_STATUS" == "failure" ]] || \
             [[ "$BACKEND_STATUS" == "failure" ]]; then
            echo "‚ùå One or more test jobs failed"
            exit 1
          else
            echo "‚úÖ All test jobs passed or were skipped"
          fi
