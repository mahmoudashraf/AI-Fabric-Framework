# AI Behavior Analytics Module v2 - Architecture Philosophy

**Version:** 2.0  
**Status:** Architecture Design  
**Date:** November 2025  
**Author:** Architecture Review

---

## ğŸ“‹ TABLE OF CONTENTS

1. [Overview](#overview)
2. [Module Goals](#module-goals)
3. [Architecture](#architecture)
4. [Data Flow](#data-flow)
5. [Core Components](#core-components)
6. [API Design](#api-design)
7. [Reusable Code](#reusable-code)
8. [Implementation Plan](#implementation-plan)

---

## ğŸ¯ OVERVIEW

The **AI Behavior Analytics Module v2** is a complete redesign focusing on:

- âœ… **Non-blocking event ingestion** (return immediately)
- âœ… **Async AI-based analysis** (scheduled workers, no rules)
- âœ… **Temporary event storage** (deleted after AI processing)
- âœ… **LLM-aware insights** (semantic embeddings)
- âœ… **Fault-tolerant processing** (DB-backed state)
- âœ… **GDPR-compliant cleanup** (automatic retention)
- âœ… **Simple API** (single endpoint for analytics)

---

## ğŸ¯ MODULE GOALS

### Primary Goals

1. **Track User Behavior Events**
   - Accept single events or batches
   - Store temporarily until processed
   - Support multiple event types (strings, no enum)

2. **AI-Based Analysis (Not Rules)**
   - Use LLM configured via ai-infrastructure-core
   - Generate insights, patterns, recommendations
   - Create semantic embeddings for search
   - Async scheduled workers (no real-time blocking)

3. **Provide Analytics to LLM**
   - REST API endpoint for user analytics
   - JSON format for LLM consumption
   - Semantic embeddings for similarity search

4. **Comply with Data Privacy**
   - Delete raw events after processing
   - Retain only AI-generated insights
   - Scheduled cleanup jobs
   - Audit trail for compliance

---

## ğŸ—ï¸ ARCHITECTURE

### High-Level Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ EVENT INGESTION LAYER                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚ POST /api/behavior/events (single)                             â”‚
â”‚ POST /api/behavior/events/batch (batch)                        â”‚
â”‚                                                                 â”‚
â”‚ Returns: 202 Accepted (non-blocking)                           â”‚
â”‚ Processing: < 5ms per event                                    â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TEMPORARY STORAGE LAYER (TTL)                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚ Table: ai_behavior_events_temp                                 â”‚
â”‚ Structure:                                                      â”‚
â”‚ â”œâ”€ id (UUID, PK)                                               â”‚
â”‚ â”œâ”€ user_id (UUID, indexed)                                     â”‚
â”‚ â”œâ”€ event_type (STRING) â† Simple, no enum                       â”‚
â”‚ â”œâ”€ event_data (JSON) â† flexible attributes                     â”‚
â”‚ â”œâ”€ source (STRING) â† web, mobile, api                          â”‚
â”‚ â”œâ”€ created_at (TIMESTAMP, indexed)                             â”‚
â”‚ â”œâ”€ processed (BOOLEAN) â† Mark for deletion                     â”‚
â”‚ â”œâ”€ processing_status (STRING) â† pending/processing/failed      â”‚
â”‚ â”œâ”€ retry_count (INT) â† 0, max 1 retry                          â”‚
â”‚ â””â”€ expires_at (TIMESTAMP, TTL)                                 â”‚
â”‚                                                                 â”‚
â”‚ TTL: Until processed OR 30 days (configurable)                â”‚
â”‚ Indexes: (user_id, created_at), (processed, expires_at)       â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ASYNC WORKER LAYER (Scheduled Processing)                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚ Scheduled Job (every 5 minutes)                                â”‚
â”‚ â”œâ”€ Query: unprocessed events from DB                           â”‚
â”‚ â”œâ”€ Batch: 1000 events per cycle (configurable)                â”‚
â”‚ â”œâ”€ Partition: By user_id (avoid conflicts)                    â”‚
â”‚ â”œâ”€ Processing:                                                 â”‚
â”‚ â”‚  â”œâ”€ Fetch events for each user                              â”‚
â”‚ â”‚  â”œâ”€ Call AIAnalyzer (LLM via ai-infrastructure-core)        â”‚
â”‚ â”‚  â”œâ”€ Generate insights/patterns/recommendations              â”‚
â”‚ â”‚  â”œâ”€ Create semantic embeddings                              â”‚
â”‚ â”‚  â”œâ”€ Store BehaviorInsights                                  â”‚
â”‚ â”‚  â””â”€ Mark as processed=true                                  â”‚
â”‚ â”‚                                                              â”‚
â”‚ â”œâ”€ Failure Handling:                                           â”‚
â”‚ â”‚  â”œâ”€ If error: increment retry_count                         â”‚
â”‚ â”‚  â”œâ”€ If retry_count < 1: retry in next cycle               â”‚
â”‚ â”‚  â”œâ”€ If retry_count >= 1: move to ai_behavior_events_failed â”‚
â”‚ â”‚  â””â”€ Log for manual inspection                               â”‚
â”‚ â”‚                                                              â”‚
â”‚ â”œâ”€ Crash Recovery:                                             â”‚
â”‚ â”‚  â”œâ”€ DB tracks processing_status                             â”‚
â”‚ â”‚  â”œâ”€ On restart: query processing_status='processing'       â”‚
â”‚ â”‚  â”œâ”€ Reset to pending (worker crashed, retry)              â”‚
â”‚ â”‚  â””â”€ Continue from last checkpoint                           â”‚
â”‚ â”‚                                                              â”‚
â”‚ â””â”€ No partitioning (for now)                                   â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AI INSIGHTS STORAGE (Permanent)                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚ Table: ai_behavior_insights                                    â”‚
â”‚ Structure:                                                      â”‚
â”‚ â”œâ”€ id (UUID, PK)                                               â”‚
â”‚ â”œâ”€ user_id (UUID, indexed)                                     â”‚
â”‚ â”œâ”€ patterns (JSON array) â† AI-generated patterns             â”‚
â”‚ â”œâ”€ insights (JSON object) â† Structured insights              â”‚
â”‚ â”œâ”€ recommendations (JSON array) â† AI recommendations          â”‚
â”‚ â”œâ”€ embeddings (VECTOR) â† For semantic search                 â”‚
â”‚ â”œâ”€ analyzed_at (TIMESTAMP)                                    â”‚
â”‚ â”œâ”€ ai_model_used (STRING) â† gpt-4o, local-model, etc        â”‚
â”‚ â”œâ”€ confidence_score (FLOAT 0-1) â† AI confidence             â”‚
â”‚ â”œâ”€ retention_until (TIMESTAMP) â† Deletion deadline           â”‚
â”‚ â””â”€ created_at (TIMESTAMP, indexed)                            â”‚
â”‚                                                                 â”‚
â”‚ REUSE: BehaviorInsights model (adapt if needed)               â”‚
â”‚ Indexes: (user_id, analyzed_at DESC), (embeddings)            â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SEMANTIC EMBEDDING LAYER                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚ Purpose: Enable semantic search on user analytics              â”‚
â”‚                                                                 â”‚
â”‚ Process:                                                        â”‚
â”‚ â”œâ”€ After AI analysis completes                                â”‚
â”‚ â”œâ”€ Convert insights/patterns to text representation           â”‚
â”‚ â”œâ”€ Call embedding service (from ai-infrastructure-core)       â”‚
â”‚ â”œâ”€ Store vector in ai_behavior_insights.embeddings           â”‚
â”‚ â””â”€ Enable: "Find similar users" queries                       â”‚
â”‚                                                                 â”‚
â”‚ REUSE: EmbeddingService from core                             â”‚
â”‚                                                                 â”‚
â”‚ Example:                                                        â”‚
â”‚   Insight text: "Power user, 45% engagement, recent,          â”‚
â”‚                  prefers mobile, high purchase value"          â”‚
â”‚   â†’ embedding: [0.23, -0.45, 0.12, ..., 0.89]               â”‚
â”‚   â†’ Store for similarity search                               â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SCHEDULED CLEANUP LAYER                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚ Cleanup Job 1: Remove Processed Events (hourly)               â”‚
â”‚ â”œâ”€ Query: WHERE processed=true AND expires_at < NOW()        â”‚
â”‚ â”œâ”€ Action: DELETE                                              â”‚
â”‚ â”œâ”€ Log: Count of deleted events                               â”‚
â”‚ â””â”€ GDPR: Fulfills "right to erasure" for raw data            â”‚
â”‚                                                                 â”‚
â”‚ Cleanup Job 2: Archive Old Insights (weekly)                  â”‚
â”‚ â”œâ”€ Query: WHERE retention_until < NOW()                       â”‚
â”‚ â”œâ”€ Action: ARCHIVE or DELETE (based on policy)               â”‚
â”‚ â”œâ”€ Log: Audit trail for compliance                            â”‚
â”‚ â””â”€ GDPR: Fulfills "data minimization"                        â”‚
â”‚                                                                 â”‚
â”‚ Cleanup Job 3: Recover Failed Events (daily)                  â”‚
â”‚ â”œâ”€ Query: processing_status='processing' AND                  â”‚
â”‚ â”‚        created_at < NOW()-1hour                            â”‚
â”‚ â”œâ”€ Action: Reset to pending (worker crash recovery)          â”‚
â”‚ â”œâ”€ Log: Recovery events for monitoring                        â”‚
â”‚ â””â”€ Reliability: Automatic crash recovery                      â”‚
â”‚                                                                 â”‚
â”‚ REUSE: Adapt BehaviorRetentionService                         â”‚
â”‚ Config: Retention policies, schedules, thresholds             â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ REST API LAYER (Single Endpoint for LLM)                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚ Endpoint: GET /api/ai/analytics/users/{userId}               â”‚
â”‚                                                                 â”‚
â”‚ Response: {                                                     â”‚
â”‚   userId: "uuid",                                             â”‚
â”‚   insights: {                                                  â”‚
â”‚     segment: "power_user",                                    â”‚
â”‚     totalEvents: 450,                                         â”‚
â”‚     primaryBehaviors: ["purchase", "engagement"],             â”‚
â”‚     riskScore: 0.15,                                          â”‚
â”‚     lastActive: "2025-11-19T10:30:00Z"                       â”‚
â”‚   },                                                           â”‚
â”‚   patterns: [                                                  â”‚
â”‚     "high_engagement",                                        â”‚
â”‚     "recent_activity",                                        â”‚
â”‚     "mobile_preference"                                       â”‚
â”‚   ],                                                           â”‚
â”‚   recommendations: [                                           â”‚
â”‚     "offer_loyalty_program",                                  â”‚
â”‚     "personalized_content"                                    â”‚
â”‚   ],                                                           â”‚
â”‚   confidence: 0.92,                                           â”‚
â”‚   analyzedAt: "2025-11-19T02:30:00Z"                         â”‚
â”‚ }                                                              â”‚
â”‚                                                                 â”‚
â”‚ Usage in LLM Prompt:                                           â”‚
â”‚   "User analytics: {{insights}}"                              â”‚
â”‚   "Patterns: {{patterns}}"                                    â”‚
â”‚   "Recommended: {{recommendations}}"                          â”‚
â”‚                                                                 â”‚
â”‚ Format: JSON (simple, LLM-friendly)                           â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š DATA FLOW - DETAILED

### Flow 1: Normal Processing (Happy Path)

```
USER EVENT
  â†“
POST /api/behavior/events
  â”œâ”€ Validate event
  â”œâ”€ Generate ID (UUID)
  â”œâ”€ INSERT into ai_behavior_events_temp
  â”‚  â””â”€ Set: processed=false, processing_status=pending
  â””â”€ Return 202 Accepted (< 5ms)
  â†“
[5 minutes later...]
ASYNC WORKER RUNS
  â”œâ”€ Query: SELECT * FROM ai_behavior_events_temp
  â”‚          WHERE processed=false
  â”‚          LIMIT 1000
  â”œâ”€ For each user_id:
  â”‚  â”œâ”€ Collect events for user
  â”‚  â”œâ”€ UPDATE: processing_status='processing'
  â”‚  â”œâ”€ Call AIAnalyzer.analyze(userId, events)
  â”‚  â”‚  â””â”€ LLM generates: patterns, insights, recommendations
  â”‚  â”œâ”€ Generate embeddings
  â”‚  â”œâ”€ INSERT into ai_behavior_insights
  â”‚  â”‚  â””â”€ Store: patterns, insights, recommendations, embeddings
  â”‚  â”œâ”€ UPDATE: processed=true
  â”‚  â””â”€ COMMIT
  â””â”€ Success! Events processed
  â†“
[Hourly...]
CLEANUP JOB 1 RUNS
  â”œâ”€ Query: DELETE FROM ai_behavior_events_temp
  â”‚          WHERE processed=true
  â””â”€ Events deleted (raw data gone)
  â†“
USER/LLM REQUESTS ANALYTICS
  â”œâ”€ GET /api/ai/analytics/users/{userId}
  â”œâ”€ Query: ai_behavior_insights (still there!)
  â””â”€ Return insights as JSON
```

### Flow 2: Failure Scenario

```
WORKER PROCESSING
  â”œâ”€ UPDATE: processing_status='processing'
  â”œâ”€ Call AIAnalyzer.analyze(...)
  â”œâ”€ ERROR! (LLM timeout, network error, etc)
  â”œâ”€ UPDATE: retry_count=1
  â””â”€ ROLLBACK (no changes)
  â†“
[5 minutes later...]
WORKER RUNS AGAIN
  â”œâ”€ Query: processing_status=pending, retry_count=0
  â”œâ”€ (Events with retry_count=1 still in queue)
  â”œâ”€ Later in cycle: Process retry_count=1 events
  â”œâ”€ Call AIAnalyzer again
  â”œâ”€ Still fails? increment retry_count=2
  â”œâ”€ Insert into ai_behavior_events_failed (manual review)
  â””â”€ Continue processing others
  â†“
[Daily...]
MANUAL REVIEW
  â”œâ”€ Query: ai_behavior_events_failed
  â”œâ”€ Investigate, fix, re-process if needed
  â””â”€ Delete when no longer needed
```

### Flow 3: Crash Recovery

```
WORKER RUNNING
  â”œâ”€ UPDATE: processing_status='processing'
  â”œâ”€ Processing event batch...
  â”œâ”€ CRASH! (server dies mid-processing)
  â””â”€ DB still shows: processing_status='processing'
  â†“
[1 hour later...]
RECOVERY JOB RUNS
  â”œâ”€ Query: WHERE processing_status='processing'
  â”‚          AND created_at < NOW()-1hour
  â”œâ”€ For each "stuck" record:
  â”‚  â”œâ”€ UPDATE: processing_status='pending'
  â”‚  â”œâ”€ UPDATE: retry_count=0 (or increment)
  â”‚  â””â”€ Log recovery event
  â””â”€ Continue processing...
  â†“
WORKER PICKS UP WHERE IT LEFT OFF
  â”œâ”€ Query: processing_status='pending'
  â”œâ”€ Processes (including recovered ones)
  â””â”€ No data loss!
```

---

## ğŸ”§ CORE COMPONENTS

### 1. Event Ingestion Service

```
File: ai-infrastructure-behavior/ingestion/BehaviorEventIngestionService.java

Responsibility:
â”œâ”€ Accept single or batch events
â”œâ”€ Validate event structure
â”œâ”€ Store to temporary table
â”œâ”€ Return immediately (non-blocking)
â””â”€ Handle duplicate detection

Reuse from v1:
â”œâ”€ ValidationUtil (if exists)
â””â”€ Event schema validation logic (adapt)
```

### 2. AI Analyzer Service

```
File: ai-infrastructure-behavior/analyzer/AIAnalyzer.java

Responsibility:
â”œâ”€ Accept user events + userId
â”œâ”€ Call LLM (via ai-infrastructure-core)
â”œâ”€ Parse LLM response
â”œâ”€ Generate patterns, insights, recommendations
â”œâ”€ Return structured BehaviorInsights

NEW! (Not rules-based)
â”œâ”€ Uses LLM configured by core
â”œâ”€ Generates semantic understanding
â””â”€ Returns confidence scores

Dependencies:
â”œâ”€ AIProviderManager (from core)
â”œâ”€ ResponseParser (JSON parsing)
â””â”€ PromptBuilder (construct LLM prompt)
```

### 3. Async Worker Service

```
File: ai-infrastructure-behavior/worker/BehaviorAnalysisWorker.java

Responsibility:
â”œâ”€ Scheduled: every 5 minutes
â”œâ”€ Query unprocessed events
â”œâ”€ Batch process (1000 at a time)
â”œâ”€ Call AIAnalyzer
â”œâ”€ Store results
â”œâ”€ Mark processed
â”œâ”€ Handle failures with retry

Crash Recovery:
â”œâ”€ Query processing_status='processing'
â”œâ”€ Check timeout (> 1 hour)
â”œâ”€ Reset to pending
â””â”€ Continue from DB state

Reuse from v1:
â”œâ”€ Worker pattern (if exists)
â””â”€ Transaction management
```

### 4. Embedding Service Integration

```
File: ai-infrastructure-behavior/embedding/BehaviorAnalyticsEmbedder.java

Responsibility:
â”œâ”€ After AI analysis completes
â”œâ”€ Convert insights to text
â”œâ”€ Call embedding service (from core)
â”œâ”€ Store vectors in ai_behavior_insights
â”œâ”€ Enable semantic search

Integration:
â”œâ”€ EmbeddingService (from ai-infrastructure-core)
â””â”€ Update ai_behavior_insights.embeddings

Reuse from v1:
â”œâ”€ BehaviorEmbeddingService (adapt)
â””â”€ Embedding storage schema
```

### 5. Cleanup Service

```
File: ai-infrastructure-behavior/cleanup/BehaviorAnalyticsCleanupService.java

Responsibility:
â”œâ”€ Job 1: Delete processed raw events (hourly)
â”œâ”€ Job 2: Archive old insights (weekly)
â”œâ”€ Job 3: Recover stuck processing (daily)
â”œâ”€ Log all deletions (audit trail)
â””â”€ GDPR compliance

Reuse from v1:
â”œâ”€ ADAPT: BehaviorRetentionService
â”œâ”€ Scheduled job pattern
â””â”€ Retention policy logic

Configuration:
â”œâ”€ Retention policies
â”œâ”€ Job schedules
â””â”€ Thresholds
```

### 6. REST API Controller

```
File: ai-infrastructure-behavior/api/BehaviorAnalyticsController.java

Endpoints:

1. POST /api/behavior/events
   â”œâ”€ Single event ingestion
   â”œâ”€ Return 202 Accepted
   â””â”€ Payload: { userId, eventType, eventData, source }

2. POST /api/behavior/events/batch
   â”œâ”€ Batch event ingestion
   â”œâ”€ Return 202 Accepted + batch_id
   â””â”€ Payload: { events: [...] }

3. GET /api/ai/analytics/users/{userId}
   â”œâ”€ Retrieve user analytics
   â”œâ”€ For LLM consumption
   â””â”€ Response: BehaviorInsights JSON
```

---

## ğŸ“¡ API DESIGN - DETAILS

### Endpoint 1: Single Event Ingestion

```
POST /api/behavior/events

Request:
{
  "userId": "550e8400-e29b-41d4-a716-446655440000",
  "eventType": "purchase",              â† String, simple
  "eventData": {
    "product_id": "prod-123",
    "amount": 99.99,
    "currency": "USD",
    "category": "electronics"
  },
  "source": "web",                      â† web, mobile, api, etc
  "timestamp": "2025-11-19T10:30:00Z"
}

Response: 202 Accepted
{
  "eventId": "550e8400-e29b-41d4-a716-446655440001",
  "status": "queued_for_analysis",
  "message": "Event accepted. Will be analyzed asynchronously."
}

Processing:
â”œâ”€ ~ 2-5ms response time (non-blocking)
â”œâ”€ Event stored in ai_behavior_events_temp
â”œâ”€ Processed by worker in next cycle
â””â”€ User gets analytics in GET /api/ai/analytics/users/{userId}
```

### Endpoint 2: Batch Event Ingestion

```
POST /api/behavior/events/batch

Request:
{
  "events": [
    {
      "userId": "550e8400-e29b-41d4-a716-446655440000",
      "eventType": "view",
      "eventData": { ... }
    },
    {
      "userId": "550e8400-e29b-41d4-a716-446655440000",
      "eventType": "click",
      "eventData": { ... }
    },
    ...
  ]
}

Response: 202 Accepted
{
  "batchId": "batch-550e8400",
  "totalEvents": 500,
  "acceptedEvents": 500,
  "status": "queued_for_analysis"
}

Processing:
â”œâ”€ Batch stored in single transaction
â”œâ”€ Status tracked by batch_id (optional)
â””â”€ Events processed individually by worker
```

### Endpoint 3: Get User Analytics (LLM-Ready)

```
GET /api/ai/analytics/users/{userId}

Query Parameters (optional):
â”œâ”€ ?latest=true        â† Get most recent analysis
â”œâ”€ ?format=json        â† Response format
â””â”€ ?include_vectors=false  â† Exclude embeddings (huge)

Response: 200 OK
{
  "userId": "550e8400-e29b-41d4-a716-446655440000",
  "analytics": {
    "insights": {
      "segment": "power_user",
      "behaviorScore": 0.87,
      "engagementLevel": "high",
      "purchaseFrequency": "weekly",
      "averageOrderValue": 150.50,
      "preferredChannel": "mobile",
      "lastActiveAt": "2025-11-19T10:30:00Z",
      "riskOfChurn": 0.05
    },
    "patterns": [
      "high_engagement",
      "recent_activity",
      "mobile_preference",
      "purchase_consistent"
    ],
    "recommendations": [
      "offer_premium_membership",
      "suggest_related_products",
      "provide_exclusive_deals"
    ],
    "aiModel": "gpt-4o",
    "confidence": 0.92,
    "analyzedAt": "2025-11-19T02:30:00Z",
    "validUntil": "2025-11-20T02:30:00Z"
  }
}

FOR LLM CONSUMPTION:

Example prompt integration:
  "User {{userId}} has these behavioral insights:
   Segment: {{insights.segment}}
   Patterns: {{patterns}}
   Recommendations: {{recommendations}}
   
   Based on this, suggest next best action..."

Format: âœ… JSON (simple, LLM-friendly, no XML/YAML)
```

---

## ğŸ“ REUSABLE CODE FROM v1 MODULE

### Models to REUSE/ADAPT

```
âœ… REUSE AS-IS:

1. BehaviorSignal
   Location: ai-infrastructure-behavior/model/BehaviorSignal.java
   Usage: Base model for events
   Changes: None needed

2. BehaviorInsights  
   Location: ai-infrastructure-behavior/model/BehaviorInsights.java
   Usage: Store AI-generated insights
   Changes: Add fields:
   â”œâ”€ embeddings (VECTOR)
   â”œâ”€ aiModel (STRING)
   â”œâ”€ confidence (DOUBLE)
   â””â”€ retentionUntil (TIMESTAMP)

ğŸ”„ ADAPT FROM v1:

1. BehaviorRetentionService
   Location: ai-infrastructure-behavior/retention/BehaviorRetentionService.java
   Current: Simple retention logic
   New Usage: Full cleanup orchestration
   Changes:
   â”œâ”€ Add Job 1: Delete processed raw events
   â”œâ”€ Add Job 2: Archive old insights
   â”œâ”€ Add Job 3: Recover stuck processing
   â””â”€ Add comprehensive logging

2. BehaviorEmbeddingService
   Location: ai-infrastructure-behavior/service/BehaviorEmbeddingService.java
   Current: Embedding generation
   New Usage: Integrate with AI insights
   Changes:
   â”œâ”€ Embed insights text (not just text fields)
   â”œâ”€ Store in ai_behavior_insights.embeddings
   â””â”€ Add similarity search queries

3. Storage/Repository Layer
   Location: ai-infrastructure-behavior/storage/
   Current: BehaviorSignalRepository
   New Usage: Add repositories:
   â”œâ”€ BehaviorEventTemporaryRepository (ai_behavior_events_temp)
   â”œâ”€ BehaviorAnalyticsInsightsRepository (ai_behavior_insights)
   â””â”€ BehaviorEventFailedRepository (ai_behavior_events_failed)

âŒ DO NOT REUSE:

1. PatternAnalyzer
   Current: Rules-based (if engagement >= 0.75...)
   New: AI-based (LLM generates patterns)
   Action: REPLACE, not adapt

2. SegmentationAnalyzer
   Current: Hardcoded segmentation logic
   New: AI generates segments
   Action: REPLACE with AIAnalyzer
```

---

## ğŸš€ IMPLEMENTATION PLAN

### Phase 1: Data Layer (3 days)

```
Tasks:
â”œâ”€ [ ] Create ai_behavior_events_temp table
â”œâ”€ [ ] Create ai_behavior_insights table (adapt from v1)
â”œâ”€ [ ] Create ai_behavior_events_failed table
â”œâ”€ [ ] Create repositories (3 new repos)
â”œâ”€ [ ] Add indexes (6 indexes total)
â””â”€ [ ] Create migration scripts

Dependencies: None (DB only)
Reuse: Storage patterns from v1

Code Files:
â”œâ”€ db/changelog/V001__create_behavior_tables.sql
â”œâ”€ storage/BehaviorEventTemporaryRepository.java
â”œâ”€ storage/BehaviorAnalyticsInsightsRepository.java
â””â”€ storage/BehaviorEventFailedRepository.java
```

### Phase 2: API Layer (2 days)

```
Tasks:
â”œâ”€ [ ] Create BehaviorEventIngestionService
â”œâ”€ [ ] Create BehaviorAnalyticsController
â”‚  â”œâ”€ POST /api/behavior/events
â”‚  â”œâ”€ POST /api/behavior/events/batch
â”‚  â””â”€ GET /api/ai/analytics/users/{userId}
â”œâ”€ [ ] Add request validation
â””â”€ [ ] Add response serialization (JSON)

Dependencies: Phase 1 (data layer)
Reuse: Validation from v1

Code Files:
â”œâ”€ api/BehaviorAnalyticsController.java
â”œâ”€ ingestion/BehaviorEventIngestionService.java
â”œâ”€ dto/BehaviorEventRequest.java
â””â”€ dto/BehaviorAnalyticsResponse.java
```

### Phase 3: AI Integration (3 days)

```
Tasks:
â”œâ”€ [ ] Create AIAnalyzer service
â”œâ”€ [ ] Integrate with ai-infrastructure-core (AIProviderManager)
â”œâ”€ [ ] Create prompt template for LLM
â”œâ”€ [ ] Create response parser (JSON)
â”œâ”€ [ ] Add error handling + retry logic
â””â”€ [ ] Test with sample events

Dependencies: Phase 1 (data), ai-infrastructure-core (LLM)
Reuse: NONE (new AI-based approach)

Code Files:
â”œâ”€ analyzer/AIAnalyzer.java
â”œâ”€ analyzer/PromptBuilder.java
â”œâ”€ analyzer/LLMResponseParser.java
â””â”€ config/AIAnalyzerProperties.java
```

### Phase 4: Async Worker (3 days)

```
Tasks:
â”œâ”€ [ ] Create BehaviorAnalysisWorker
â”œâ”€ [ ] Implement @Scheduled(fixedRate=300000)
â”œâ”€ [ ] Batch processing (1000 events/cycle)
â”œâ”€ [ ] Error handling + retry logic
â”œâ”€ [ ] Crash recovery logic
â””â”€ [ ] Add monitoring/metrics

Dependencies: Phase 3 (AI)
Reuse: Worker patterns from v1

Code Files:
â”œâ”€ worker/BehaviorAnalysisWorker.java
â”œâ”€ worker/WorkerHealthMonitor.java
â””â”€ config/WorkerProperties.java
```

### Phase 5: Embedding Integration (2 days)

```
Tasks:
â”œâ”€ [ ] Adapt BehaviorEmbeddingService
â”œâ”€ [ ] Embed insights after AI analysis
â”œâ”€ [ ] Store vectors in ai_behavior_insights
â”œâ”€ [ ] Add similarity search capability
â””â”€ [ ] Test with sample data

Dependencies: Phase 3 (AI) + Phase 4 (Worker)
Reuse: BehaviorEmbeddingService from v1

Code Files:
â”œâ”€ embedding/BehaviorAnalyticsEmbedder.java
â””â”€ embedding/EmbeddingStorageService.java
```

### Phase 6: Cleanup Layer (2 days)

```
Tasks:
â”œâ”€ [ ] Adapt BehaviorRetentionService
â”œâ”€ [ ] Implement Job 1: Delete processed events
â”œâ”€ [ ] Implement Job 2: Archive old insights
â”œâ”€ [ ] Implement Job 3: Crash recovery
â”œâ”€ [ ] Add comprehensive logging
â””â”€ [ ] Add audit trail

Dependencies: Phase 1 (data layer)
Reuse: BehaviorRetentionService, retention logic

Code Files:
â”œâ”€ cleanup/BehaviorAnalyticsCleanupService.java
â”œâ”€ cleanup/ProcessedEventCleanupJob.java
â”œâ”€ cleanup/InsightArchivalJob.java
â””â”€ cleanup/CrashRecoveryJob.java
```

### Phase 7: Testing & Integration (3 days)

```
Tasks:
â”œâ”€ [ ] Unit tests (services)
â”œâ”€ [ ] Integration tests (full flow)
â”œâ”€ [ ] Performance tests (1M events/day)
â”œâ”€ [ ] Failure scenario tests
â”œâ”€ [ ] Documentation
â””â”€ [ ] Demo

Dependencies: All phases
Tests:
â”œâ”€ BehaviorAnalysisWorkerTest.java
â”œâ”€ AIAnalyzerIntegrationTest.java
â”œâ”€ EndToEndFlowTest.java
â””â”€ CrashRecoveryTest.java
```

---

## ğŸ“‹ CONFIGURATION

```properties
# application.yml

ai:
  behavior:
    ingestion:
      max-batch-size: 1000
      duplicate-detection: true
      
    worker:
      enabled: true
      schedule: "0 */5 * * * *"     # Every 5 minutes
      batch-size: 1000
      max-retries: 1
      
    storage:
      temp-ttl-hours: 24            # Delete after 24h
      temp-retention-after-process: false  # Delete when processed
      
    embedding:
      enabled: true
      model: "all-MiniLM-L6-v2"
      batch-size: 100
      
    cleanup:
      job1-schedule: "0 0 * * * *"  # Every hour
      job2-schedule: "0 0 0 * * 0"  # Weekly
      job3-schedule: "0 0 * * * *"  # Every hour
      
    retention:
      insights-retention-days: 90
      failed-events-retention-days: 30
      
    ai-provider:
      type: "gpt-4o"                # From ai-infrastructure-core
      fallback: "local-onnx"
```

---

## ğŸ¯ KEY DESIGN DECISIONS

| Decision | Rationale | Impact |
|----------|-----------|--------|
| **Async Workers** | Scale + non-blocking | 5min latency acceptable |
| **Temp Storage TTL** | GDPR compliance + cost | Raw events deleted after 24h |
| **AI-based (not rules)** | Better insights + semantic | Requires LLM provider |
| **DB-backed state** | Crash recovery | Single worker bottleneck (for now) |
| **Event types as strings** | Flexibility | No validation (mitigated by schema) |
| **Single analytics endpoint** | LLM simplicity | Limited querying |
| **Retry once then fail** | Simplicity | Some events lost (mitigated by monitoring) |
| **No partitioning** | MVP scope | Won't scale to 100M events/day yet |

---

## âœ… DONE CORRECTLY

vs v1:

| Aspect | v1 (Rules) | v2 (AI-Based) |
|--------|-----------|---------------|
| **Analysis** | Synchronous | âœ… Async |
| **AI** | Rules-based | âœ… LLM-based |
| **Storage** | Permanent | âœ… Temp + permanent |
| **Cleanup** | None | âœ… Automated + GDPR |
| **Failure Handling** | None | âœ… Retry + recovery |
| **API** | Multiple endpoints | âœ… Single endpoint |
| **Scalability** | Limited | â³ Medium (improved) |
| **LLM Integration** | Optional | âœ… Native |

---

## ğŸ“ SUMMARY

**v2 Module delivers:**

âœ… Non-blocking event ingestion (< 5ms response)
âœ… Async LLM-based analysis (configurable schedules)
âœ… GDPR-compliant data lifecycle (temporary â†’ delete)
âœ… Semantic embeddings for intelligent search
âœ… Fault-tolerant processing (crash recovery)
âœ… Simple REST API for LLM consumption
âœ… Comprehensive cleanup & auditing

**Effort: 2-3 weeks, team of 2**

**Risks:**
- âš ï¸ LLM provider dependency (rate limits, costs)
- âš ï¸ Worker bottleneck at 100M+ events/day
- âš ï¸ Retry-once loses some events (needs monitoring)

**Future Improvements:**
- ğŸ”® Partitioning by user_id for scale
- ğŸ”® Multiple worker instances
- ğŸ”® Event streaming (Kafka) instead of polling
- ğŸ”® Real-time notifications on important patterns


