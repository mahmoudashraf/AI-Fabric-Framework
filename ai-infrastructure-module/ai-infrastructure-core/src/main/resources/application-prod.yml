# Production Configuration - Vector Database
ai:
  pii-detection:
    enabled: true
    mode: REDACT
    store-encrypted-original: true
    encryption-secret: ${PII_ENCRYPTION_SECRET:}

  smart-suggestions:
    enabled: true
    min-confidence: ${AI_SMART_SUGGESTIONS_MIN_CONFIDENCE:0.70}
    primary-confidence: ${AI_SMART_SUGGESTIONS_PRIMARY_CONFIDENCE:0.85}
    retrieval-limit: ${AI_SMART_SUGGESTIONS_LIMIT:3}
    retrieval-threshold: ${AI_SMART_SUGGESTIONS_THRESHOLD:0.55}

  response-sanitization:
    enabled: true
    force-redaction: true
    high-risk-warning-message: ${AI_RESPONSE_SANITIZATION_WARNING:SENSITIVE INFORMATION REMOVED.}
    medium-risk-warning-message: ${AI_RESPONSE_SANITIZATION_MEDIUM_WARNING:PERSONAL INFORMATION REDACTED BEFORE DELIVERY.}
    warning-enabled: ${AI_RESPONSE_SANITIZATION_WARNING_ENABLED:true}
    warning-level-high-risk: ${AI_RESPONSE_SANITIZATION_WARNING_LEVEL_HIGH:BLOCK}
    warning-level-medium-risk: ${AI_RESPONSE_SANITIZATION_WARNING_LEVEL_MEDIUM:WARN}
    guidance-enabled: ${AI_RESPONSE_SANITIZATION_GUIDANCE_ENABLED:true}
    guidance-message: ${AI_RESPONSE_SANITIZATION_GUIDANCE:Please route sensitive requests through secure support.}
    suggestion-limit: ${AI_RESPONSE_SANITIZATION_SUGGESTION_LIMIT:3}
    include-suggestion-metadata: ${AI_RESPONSE_SANITIZATION_SUGGESTION_METADATA:true}
    publish-events: ${AI_RESPONSE_SANITIZATION_PUBLISH_EVENTS:true}

  intent-history:
    enabled: true
    retention-days: ${AI_INTENT_HISTORY_RETENTION_DAYS:90}
    cleanup-cron: ${AI_INTENT_HISTORY_CLEANUP_CRON:0 0 * * * *}
    store-encrypted-query: ${AI_INTENT_HISTORY_STORE_ENCRYPTED_QUERY:true}

  providers:
    # Embedding Provider Configuration
    # Options: onnx (local), rest (Docker service), openai (cloud API)
    embedding-provider: ${EMBEDDING_PROVIDER:openai}

    # ONNX Configuration (for local embeddings)
    onnx-model-path: ${ONNX_MODEL_PATH:classpath:/models/embeddings/all-MiniLM-L6-v2.onnx}
    onnx-tokenizer-path: ${ONNX_TOKENIZER_PATH:classpath:/models/embeddings/tokenizer.json}
    onnx-max-sequence-length: 512
    onnx-use-gpu: ${ONNX_USE_GPU:false}

    # REST Configuration (for Docker/sentence-transformers service)
    rest-base-url: ${REST_EMBEDDING_URL:http://localhost:8000}
    rest-endpoint: /embed
    rest-batch-endpoint: /embed/batch
    rest-timeout: 30000
    rest-model: all-MiniLM-L6-v2
    
    # OpenAI Configuration (production fallback)
    openai-api-key: ${OPENAI_API_KEY:}
    openai-embedding-model: text-embedding-3-small
    openai-timeout: 60
  
  vector-db:
    type: pinecone
    pinecone:
      apiKey: ${PINECONE_API_KEY:}
      environment: "us-east-1-aws"
      indexName: "ai-infrastructure-prod"
      dimensions: 1536
      metric: "cosine"
      pods: 2
      podType: "p1"
      enableMetadataFiltering: true

# Logging configuration for production
logging:
  level:
    com.ai.infrastructure.rag: INFO
    com.ai.infrastructure.service.VectorManagementService: INFO
    com.ai.infrastructure.service.AICapabilityService: INFO