# Test Configuration - Vector Database and OpenAI
ai:
  pii-detection:
    enabled: true
    mode: DETECT_ONLY
    store-encrypted-original: false

  smart-suggestions:
    enabled: true
    min-confidence: 0.65
    primary-confidence: 0.85
    retrieval-limit: 2
    retrieval-threshold: 0.55

  response-sanitization:
    enabled: true
    force-redaction: true
    suggestion-limit: 2
    medium-risk-warning-message: "Some details were removed for testing safety."
    warning-enabled: true
    warning-level-high-risk: BLOCK
    warning-level-medium-risk: WARN
    guidance-enabled: true
    guidance-message: "Test guidance: avoid storing PII in fixtures."
    include-suggestion-metadata: true
    publish-events: true

  intent-history:
    enabled: true
    retention-days: 30
    cleanup-cron: "0 0 * * * *"
    store-encrypted-query: false

  vector-db:
    type: memory
    memory:
      enablePersistence: false
      persistencePath: "./data/memory-vector-store.json"
      maxVectors: 1000
      enableCleanup: true
      cleanupIntervalMinutes: 5
      maxVectorAgeMinutes: 30
  providers:
    llm-provider: ${LLM_PROVIDER:openai}
    embedding-provider: ${EMBEDDING_PROVIDER:openai}
    enable-fallback: true

    onnx:
      enabled: ${ONNX_ENABLED:false}
      model-path: ${ONNX_MODEL_PATH:classpath:/models/embeddings/all-MiniLM-L6-v2.onnx}
      tokenizer-path: ${ONNX_TOKENIZER_PATH:classpath:/models/embeddings/tokenizer.json}
      max-sequence-length: 512
      use-gpu: false
      model-alias: all-MiniLM-L6-v2

    openai:
      enabled: true
      api-key: ${OPENAI_API_KEY:sk-test-key}
      model: gpt-4o-mini
      embedding-model: text-embedding-3-small
      max-tokens: 1000
      temperature: 0.3
      timeout: 30
      priority: 100

# Logging configuration for tests
logging:
  level:
    com.ai.infrastructure.rag: DEBUG
    com.ai.infrastructure.service.VectorManagementService: DEBUG
    com.ai.infrastructure.service.AICapabilityService: DEBUG